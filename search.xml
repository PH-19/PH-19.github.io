<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Docker</title>
    <url>/2021/04/02/Docker/</url>
    <content><![CDATA[<h1 id="Docker使用"><a href="#Docker使用" class="headerlink" title="Docker使用"></a>Docker使用</h1><p><code>service docker start</code>启动</p>
<h2 id="Docker容器命令"><a href="#Docker容器命令" class="headerlink" title="Docker容器命令"></a>Docker容器命令</h2><p><code>docker run[OPTIONS]IMAGE[COMMAND][ARG...]</code>新建并启动新的容器</p>
<blockquote>
<p>OPTIONS说明：</p>
<p>–name=”new name”:为容器指定一个名称</p>
<p>-d:后台运行容器并返回容器ID</p>
<p>-i:以交互模式运行容器</p>
<p>-t:为容器重新分配一个伪终端</p>
<p>-p:主机端口:docker容器端口</p>
<p>-P:随机分配端口</p>
</blockquote>
<p><code>docker ps[OPTIONS]</code>查看容器</p>
<blockquote>
<p>OPTIONS说明：</p>
<p>-a:列出当前所有活跃容器以及曾运行过的容器</p>
<p>-l:显示最近创建的容器</p>
<p>-n:显示最近n个创建的容器</p>
<p>-q:静默模式，只显示容器编号</p>
<p>–no-trunc:不截断输出</p>
</blockquote>
<p><code>exit</code>停止并退出当前容器</p>
<p><code>ctrl</code>+<code>P</code>+<code>Q</code>容器不停止退出</p>
<p><code>docker start+container name/container ID</code> 启动容器</p>
<p><code>docker restart+container name/container ID</code> 重新启动容器</p>
<p><code>docker stop+container name/container ID</code> 停止容器</p>
<p><code>docker kill+container name/container ID</code> 强制停止容器</p>
<p><code>docker rm+container name/container ID</code> 删除已停止的某一容器</p>
<p><code>docker -rm -f+container name/container ID</code> 删除正在运行的容器</p>
<p><code>docker logs -f -t --tail</code> -t加入时间戳 -f跟随最新的打印日志 –tail数字显示最后多少条</p>
<p><code>docker top+container ID</code> 查看容器内运行的进程</p>
<p><code>docker inspect+container ID</code> 查看容器内部细节</p>
<p><code>docker attach+container ID</code>  重新进入容器，启动命令的终端，不会启动新的进程</p>
<p><code>docker exec -it+container ID</code>  重新进入容器，在容器中打开新的终端，并且可以启动新的进程</p>
<p><code>docker cp+container ID:path_in_container target_path</code> 将容器中的文件拷贝到目标路径 </p>
<hr>
<h2 id="Docker镜像命令"><a href="#Docker镜像命令" class="headerlink" title="Docker镜像命令"></a>Docker镜像命令</h2><p><code>docker pull ...</code> 拉取镜像</p>
<p><code>docker images[OPTIONS]</code> 查看本地镜像</p>
<blockquote>
<p>OPTIONS说明：</p>
<p>-a:列出本地所有的镜像（含中间映像层）</p>
<p>-q:只显示镜像ID</p>
<p>–digests:显示镜像的摘要信息</p>
<p>–no-trunc:显示完整的镜像信息</p>
</blockquote>
<p><code>docker search+image name[OPTIONS]</code> 搜索镜像</p>
<blockquote>
<p>OPTIONS说明：</p>
<p>–no-trunc:显示完整的镜像描述</p>
<p>–automated:只列出automated build类型的镜像</p>
</blockquote>
<p><code>docker pull+image name</code> 拉取某个镜像</p>
<p><code>docker rmi+image name/image ID</code> 删除某个镜像</p>
<p><code>docker rmi+image name/image ID1+image name/image ID2+...</code> 删除多个镜像</p>
<p><code>docker rmi -f $(docker images -qa)</code> 删除全部镜像</p>
<p><code>docker commit -m=&quot;提交的描述信息&quot; -a=&quot;作者&quot; 容器ID 要创建的目标镜像名:[标签名]</code> 生成新镜像</p>
<hr>
<h2 id="Docker数据卷"><a href="#Docker数据卷" class="headerlink" title="Docker数据卷"></a>Docker数据卷</h2><p>Features：</p>
<ol>
<li>数据卷可在容器之间共享或者重用数据</li>
<li>卷中的更改可以直接生效</li>
<li>数据卷中的更改不会包含在镜像的更新中</li>
<li>数据卷的生命周期一直持续到没有容器使用它为止</li>
</ol>
<p>Commands:</p>
<p><code>docker run -it -v /宿主机绝对路径目录:/容器内目录 镜像名</code> 在两个路径创建分别创建文件夹并使它们相关</p>
<p><code>docker run -it -v /宿主机绝对路径目录:/容器内目录:ro 镜像名</code> 仅允许主机对数据卷内容进行修改，容器仅有读取数据卷内容的权限</p>
<p>在Dockerfile中使用VOLUME指令                                                                            <code>VOLUME [&quot;/dataVolumeContainer1&quot;,&quot;/dataVolumeContainer2&quot;]</code> 指定两个容器内部数据卷的地址</p>
<p><code>docker run -it --name ContainerName --volumes-from FatherName ImageName</code> 新建镜像并使其指定路径连接数据卷</p>
<hr>
<h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>流程：</p>
<ol>
<li><p>编写dockerfile文件</p>
</li>
<li><p>docker build -t 新镜像名字:TAG</p>
</li>
<li><p>docker run -it 新镜像名字:TAG</p>
</li>
<li><p>列出镜像的变更历史 docker history 镜像ID</p>
<p>重点：</p>
</li>
<li><p>每条保留字指令都必须为大写字母并且后面至少跟随一个参数</p>
</li>
<li><p>#表示注释</p>
</li>
<li><p>每条指令都会创建一个新的镜像层，并对镜像进行提交  </p>
</li>
</ol>
<p>Docker执行Dockerfile的流程：</p>
<ol>
<li>docker从基础镜像运行一个容器</li>
<li>执行一条指令并对容器作出修改</li>
<li>提交一个新的镜像层</li>
<li>docker基于新提交的镜像运行一个新容器</li>
<li>执行dockerfile中的下一条指令知道所有指令执行完成</li>
</ol>
<p>Dockerfile保留字指令：</p>
<blockquote>
<p>FROM 基础镜像；当前镜像基于哪个镜像</p>
<p>MAINTAINER 镜像维护者的姓名和邮箱地质=址</p>
<p>RUN 容器构建时所需命令</p>
<p>EXPOSE 当前容器对外暴露的端口</p>
<p>WORKDIR 指定在创建容器后，终端默认登陆的进来工作目录。不添加即为根目录</p>
<p>ENV 用于在构建镜像过程中设置环境变量</p>
<p>ADD 将宿主机目录下的文件拷贝进镜像且自动处理URL、解压tar压缩包</p>
<p>COPY 拷贝文件和目录到镜像中，将从构建上下文目录中源路径的文件/目录复制到新的一层镜像内的目标路径位置</p>
<p>VOLUME 容器数据卷，用于数据保存和持久化工作</p>
<p>CMD 指定一个容器启动时要运行的命令。可以有多个CMD命令，但只有最后一个会生效，会被docker run之后的参数替代</p>
<p>ENTRYPOINT 指定一  个容器启动时要运行的命令，指定容器启动程序及参数</p>
<p>ONBUILD 当构建一个被继承的dockerfile时运行，父镜像在被子镜像继承后其onbuild被触发</p>
</blockquote>
<hr>
<hr>
]]></content>
  </entry>
  <entry>
    <title>交叉熵损失函数.md</title>
    <url>/2021/04/18/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h1 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h1><h3 id="一、损失函数"><a href="#一、损失函数" class="headerlink" title="一、损失函数"></a>一、损失函数</h3><p><strong>在一个训练循环(training loop)内会发生:</strong></p>
<p>(1) 抽取训练样本 x 和对应目标 y 组成的数据批量。<br>(2) 在 x 上运行网络[这一步叫作前向传播(forward pass)],得到预测值 y_prediction 。<br>(3) 计算网络在这批数据上的损失,用于衡量 y_prediction 和 y 之间的距离。<br>(4) 计算损失相对于网络参数的梯度[一次反向传播(backward pass)]。<br>(5) 将参数沿着梯度的反方向移动一点,比如 W -= step * gradient ,从而使这批数据上的损失减小一点。        </p>
<pre class="mermaid">graph LR;
Input_X-->Layer1
subgraph  
Weight1-->Layer1
end
Layer1-->Layer2
subgraph   
Weight2-->Layer2
end
Layer2-->Prediction_Y'
Prediction_Y'-->Loss_Function
True_target_Y-->Loss_Function
Loss_Function-->Loss
subgraph    
Loss-->Optimizer
Optimizer-->Weight2
Optimizer-->Weight1
end</pre>

<p>​        想要控制一件事物,首先需要能够观察它。想要控制神经网络的输出,就需要能够衡量该输出与预期值之间的距离。这是神经网络**损失函数(loss function)<strong>的任务,该函数也叫</strong>目标函数(objective function)**。损失函数的输入是网络预测值与真实目标值(即你希望网络输出的结果),然后计算一个距离值,衡量该网络在这个示例上的效果好坏。</p>
<blockquote>
<p>​        具有多个输出的神经网络可能具有多个损失函数(每个输出对应一个损失函数)。但是,梯度下降过程必须基于单个标量损失值。因此,对于具有多个损失函数的网络,需要将所有损失函数取平均,变为一个标量值。选择正确的目标函数对解决问题是非常重要的。<strong>网络的目的是使损失尽可能最小化,因此,如果目标函数与成功完成当前任务不完全相关,那么网络最终得到的结果可能会不符合你的预期。</strong>想象一下,利用 SGD训练一个愚蠢而又无所不能的人工智能,给它一个蹩脚的目标函数:“将所有活着的人的平均幸福感最大化”。为了简化自己的工作,这个人工智能可能会选择杀死绝大多数人类,只留几个人并专注于这几个人的幸福——因为平均幸福感并不受人数的影响。这可能并不是你想要的结果!</p>
<p>​        请记住,你构建的所有神经网络在降低损失函数时和上述的人工智能一样无情。因此,一定要明智地择目标函数,否则你将会遇到意想不到的副作用。幸运的是,对于分类、回归、序列预测等常见问题,你可以遵循一些简单的指导原则来选择正确的损失函数。例如,对于<strong>二分类问题,你可以使用二元交叉熵(binary crossentropy)损失函数;对于多分类问题,可以用分类交叉熵(categorical crossentropy)损失函数</strong>;对于回归问题,可以用均方误差(mean-squared error)损失函数;对于序列学习问题,可以用联结主义时序(CTC,connectionist temporal classification)损失函数,等等。只有在面对真正全新的研究问题时,你才需要自主开发目标函数。</p>
</blockquote>
<h3 id="二、交叉熵"><a href="#二、交叉熵" class="headerlink" title="二、交叉熵"></a>二、交叉熵</h3><p>​        交叉熵是信息论中的一个概念，要想了解交叉熵的本质，需要先从最基本的概念讲起。</p>
<h3 id="2-1相对熵-KL散度"><a href="#2-1相对熵-KL散度" class="headerlink" title="2.1相对熵(KL散度)"></a>2.1相对熵(KL散度)</h3><p>​        如果对于同一个随机变量有两个单独的概率分布P(x)和Q(x)，则我们可以使用KL散度来衡量这两个概率分布之间的差异。</p>
<p>下面直接列出公式，再举例子加以说明。<br>$$<br>D <em>{KL} (p∣∣q)= \sum</em>{i=1}^{n} p(x_i)log(q(x_i)/p(x_i))<br>$$</p>
<p>例：在机器学习中，常常<strong>使用P(x)来表示样本的真实分布，Q(x)来表示模型所预测的分布</strong>，比如在一个三分类任务中（例如，猫狗马分类器x1,x2,x3分别代表猫，狗，马。例如一张猫的图片真实分布P(X)=[1,0,0] , 预测分布Q(X)=[0.7,0.2,0.1]计算KL散度：<br>$$<br>D_{KL}(p∣∣q)=\sum_{i=1}^{n}p(x_i)log(q(x_i)/p(x_i))<br>$$</p>
<p>$$<br>=p(x _1)log(q(x_1)/p(x_1))+p(x_2)log(q(x_2)/p(x_2))+p(x_3)log(q(x_3)/p(x_3))<br>$$</p>
<p>$$<br>=1∗log( 0.7/1)=0.36<br>$$</p>
<p>KL散度越小，表示P(x)与Q(x)的分布更加接近，可以通过反复训练Q(x)来使Q(x)的分布逼近P(x)。</p>
<h3 id="2-2信息量"><a href="#2-2信息量" class="headerlink" title="2.2信息量"></a>2.2信息量</h3><p>​        信息论奠基人香农（Claude Elwood Shannon）认为“信息是用来消除随机不确定性的东西”，也就是说<strong>衡量信息量的大小就是看这个信息消除不确定性的程度</strong>。</p>
<p>​        “太阳从东边升起”，这条信息并没有减少不确定性，因为太阳肯定是从东边升起的，这是一句废话，信息量为0。”2022年中国队成功进入世界杯“，从直觉上来看，这句话具有很大的信息量。因为中国队进入世界杯的不确定性因素很大，而这句话消除了进入世界杯的不确定性，所以按照定义，这句话的信息量很大。</p>
<p>​        根据上述可总结如下：<strong>信息量的大小与信息发生的概率成反比</strong>。概率越大，信息量越小。概率越小，信息量越大。</p>
<p>​        设某一事件发生的概率为P(x)，其信息量表示为：<br>$$<br>I(x)=−log(P(x))<br>$$<br>其中I(x)表示信息量，log表示以e为底的自然对数。</p>
<h3 id="2-3信息熵"><a href="#2-3信息熵" class="headerlink" title="2.3信息熵"></a>2.3信息熵</h3><p>​        信息熵也被称为熵，用来表示所有信息量的期望。期望是试验中每次可能结果的概率乘以其结果的总和。</p>
<p>所以信息量的熵可表示为：（这里的是一个离散型随机变量）<br>$$<br>H(X)=− \sum_{i=1}^{n} P(x_i)log(P(x_i )))(X=x _1,x_2 ,x_3…,x_n)<br>$$<br>​        例：使用明天的天气概率来计算其信息熵：</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>事件</th>
<th>概率P</th>
<th>信息量</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>明天是晴天</td>
<td>0.5</td>
<td>-log(0.5)</td>
</tr>
<tr>
<td>2</td>
<td>明天是雨天</td>
<td>0.2</td>
<td>-log(0.2)</td>
</tr>
<tr>
<td>3</td>
<td>多云</td>
<td>0.3</td>
<td>-log(0.3)</td>
</tr>
</tbody></table>
<p>$$<br>H(X)=−(0.5∗log(0.5)+0.2∗log(0.2)+0.3∗log(0.3))<br>$$</p>
<p>​        对于0-1分布的问题，由于其结果只用两种情况，是或不是，设某一件事情发生的概率为P(x)，则另一件事情发生的概率为1−P(x) ，所以对于0-1分布的问题，计算熵的公式可以简化如下：<br>$$<br>H(X)=−<br>\sum_{n=1}^{n} P(x_ilog(P(x_i)))<br>$$</p>
<p>$$<br>=−[P(x)log(P(x))+(1−P(x))log(1−P(x))]<br>$$</p>
<p>$$<br>=−P(x)log(P(x))−(1−P(x))log(1−P(x))<br>$$</p>
<h3 id="2-4交叉熵"><a href="#2-4交叉熵" class="headerlink" title="2.4交叉熵"></a>2.4交叉熵</h3><p>​        首先将KL散度公式拆开：<br>$$<br>D_{KL}(p∣∣q)=\sum_{i=1}^{n}p(x_i))log(p(x_i)/q(x_i))<br>$$</p>
<p>$$<br>= \sum_{i=1}^{n}p(x_i)log(p(x_i))− \sum_{i=1}^{n}p(x_i)log(q(x_i))<br>$$</p>
<p>$$<br>=−H(p(x))+[-\sum_{i=1}^{n}p(x_i)log(q(x_i))]<br>$$</p>
<p>​        前者H(p(x))表示信息熵，后者即为交叉熵，KL散度=信息熵+交叉熵</p>
<p>交叉熵公式表示为：<br>$$<br>H(p,q)=-\sum_{i=1}^{n}p(x_i)log(q(x_i))<br>$$<br>​        在机器学习训练网络时，<strong>输入数据与标签常常已经确定，那么真实概率分布P(x)也就确定下来了</strong>，所以信息熵在这里就是一个常量。由于KL散度的值表示真实概率分布P(x)与预测概率分布Q(x)之间的差异，值越小表示预测的结果越好，所以需要最小化KL散度，而交叉熵等于KL散度加上一个常量（信息熵），且公式相比KL散度更加容易计算，所以在机器学习中常常使用交叉熵损失函数来计算loss就行了。</p>
<p><strong>在线性回归问题中，常常使用MSE(Mean Squared Error)作为loss函数，而在分类问题中常常使用交叉熵作为Loss函数。</strong></p>
<h3 id="2-5交叉熵在单分类问题中的应用"><a href="#2-5交叉熵在单分类问题中的应用" class="headerlink" title="2.5交叉熵在单分类问题中的应用"></a>2.5交叉熵在单分类问题中的应用</h3><p>​        这里的单类别是指，每一张图像样本只能有一个类别，比如只能是狗或只能是猫。<br>$$<br>loss=-\sum_{i=1}^{n}y_ilog(\hat{y_i})<br>$$<br>​        上式为一张样本的loss计算方法。其中n代表着n种类别。</p>
<p><img src="https://img-blog.csdn.net/20180125164444783?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdHN5Y2NuaA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>标签与预测值如下：</p>
<table>
<thead>
<tr>
<th>*</th>
<th>猫</th>
<th>青蛙</th>
<th>老鼠</th>
</tr>
</thead>
<tbody><tr>
<td>Label</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>Pred</td>
<td>0.3</td>
<td>0.6</td>
<td>0.1</td>
</tr>
</tbody></table>
<p>那么Loss为：<br>$$<br>loss=−(0∗log(0.3)+1∗log(0.6)+0∗log(0.1))=-log(0.6)<br>$$</p>
<p>$$<br>loss=-\sum_{i=1}^{n}y_ilog(\hat{y_i})<br>$$<br>​        上式为一张样本的loss计算方法。其中n代表着n种类别。</p>
<p>​        对应一个batch的loss就是<br>$$<br>loss=-\frac{1}{m}\sum_{j=1}^m\sum_{i=1}^{n}y_{ji}log(\hat{y_{ji}})<br>$$</p>
<blockquote>
<p>参考：</p>
<p>1.<a class="link"   href="https://blog.csdn.net/tsyccnh/article/details/79163834" >https://blog.csdn.net/tsyccnh/article/details/79163834<i class="fas fa-external-link-alt"></i></a></p>
<p>2.<a class="link"   href="https://blog.csdn.net/b1055077005/article/details/100152102?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161866653316780261961175%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=161866653316780261961175&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-100152102.pc_search_result_no_baidu_js&amp;utm_term=%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0" >https://blog.csdn.net/b1055077005/article/details/100152102?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161866653316780261961175%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=161866653316780261961175&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-100152102.pc_search_result_no_baidu_js&amp;utm_term=%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0<i class="fas fa-external-link-alt"></i></a></p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>ROS-package.md</title>
    <url>/2021/07/04/ROS-package/</url>
    <content><![CDATA[<h2 id="ROS-package"><a href="#ROS-package" class="headerlink" title="ROS-package"></a>ROS-package</h2><h5 id="package文件结构"><a href="#package文件结构" class="headerlink" title="package文件结构"></a>package文件结构</h5><pre class="mermaid">graph TD;
package-->CMakeLists.txt
package-->package.xml
package-->scripts
scripts-->.sh
scripts-->.py
package-->include
include-->.h
package-->src
src-->.cpp
package-->msg
msg-->.msg
package-->srv
srv-->.srv
package-->launch
launch-->.launch</pre>

<blockquote>
<p>CMakeLists.txt 编译的指导文件</p>
<p>package.xml 功能包的背景信息</p>
<p>scripts 脚本文件</p>
<p>include c++头文件</p>
<p>src c++文件</p>
<p>msg 自定义消息类型</p>
<p>srv 自定义消息类型</p>
<p>launch launch文件</p>
</blockquote>
<h5 id="package常用指令"><a href="#package常用指令" class="headerlink" title="package常用指令"></a>package常用指令</h5><p><code>rospack</code></p>
<blockquote>
<p><code>rospack find &lt;package_name&gt; </code>查找特定package的地址</p>
<p><code> rospack list</code>列出本地所有package</p>
</blockquote>
<p><code>roscd</code></p>
<blockquote>
<p><code>roscd &lt;package_name&gt;</code> 跳转到某个特定package的路径</p>
</blockquote>
<p><code>rosls</code></p>
<blockquote>
<p><code>rosls &lt;package_name&gt;</code> 列举某个package的文件信息</p>
</blockquote>
<p><code>rosed</code></p>
<blockquote>
<p><code>rosed &lt;package_name&gt; &lt;file_name&gt;</code> 编辑package里的文件</p>
</blockquote>
<p><code>catkin_create_pkg</code></p>
<blockquote>
<p><code>catkin_create_pkg [deps]</code> 创建一个package</p>
</blockquote>
<p><code>rosdep</code></p>
<blockquote>
<p><code>rosdep install [package_name]</code> 安装某个package所需的依赖</p>
</blockquote>
]]></content>
  </entry>
</search>
